# ChungKhoanAI - Há»‡ Thá»‘ng Dá»± ÄoÃ¡n Chá»©ng KhoÃ¡n TiÃªn Tiáº¿n

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n chá»©ng khoÃ¡n Viá»‡t Nam sá»­ dá»¥ng **Deep Learning** vá»›i kiáº¿n trÃºc **TCN-Residual** (Temporal Convolutional Network) vÃ  **Multi-Horizon Prediction** cho phÃ¢n tÃ­ch thá»‹ trÆ°á»ng chá»©ng khoÃ¡n.

## ğŸ—ï¸ Tá»•ng Quan Kiáº¿n TrÃºc

### MÃ´ HÃ¬nh TCN-Residual
Kiáº¿n trÃºc TCN phá»©c táº¡p vá»›i multi-task learning:

```
Input LÃ—d (L=60, d=65 features)
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=1) + LayerNorm + ReLU + Dropout(0.1)
     Residual add
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=2) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=4) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=8) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> Squeeze-Excitation (channel attention)
 â””â”€> GlobalAvgPool (theo thá»i gian)
 â””â”€> Multi-Horizon Heads:
     â”œâ”€> Regression: Dense(64) â†’ Dense(3) â†’ log-return @5,10,20 days
     â””â”€> Classification: Dense(64) â†’ Dense(3, sigmoid) â†’ direction @5,10,20 days
```

### TÃ­nh NÄƒng ChÃ­nh

- **Multi-Horizon Prediction**: Dá»± Ä‘oÃ¡n log-return vÃ  hÆ°á»›ng táº¡i 3 horizon (5, 10, 20 ngÃ y)
- **MC-Dropout Uncertainty**: Æ¯á»›c lÆ°á»£ng uncertainty vá»›i 20 forward passes
- **Advanced Loss Functions**: Huber loss hoáº·c Pinball loss vá»›i Î»Â·BCE
- **Ensemble Strategy**: 5 seeds Ã— 2 window sizes Ã— multiple architectures
- **Walk-Forward Validation**: XÃ¡c thá»±c chuá»—i thá»i gian thá»±c táº¿
- **Paper Trading**: Backtesting vá»›i uncertainty-aware entry rules

## ğŸ“‹ Äáº·c Táº£ MÃ´ HÃ¬nh

### Tham Sá»‘ Kiáº¿n TrÃºc
- **Äá»™ dÃ i Cá»­a sá»• (L)**: 60 (chÃ­nh), 90 (ensemble)
- **KÃ­ch thÆ°á»›c Kernel (k)**: 5
- **Filters**: 64 (cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘áº¿n 96-128)
- **Dilations**: [1, 2, 4, 8]
- **MC-Dropout**: 0.1 á»Ÿ output heads
- **Activation**: ReLU + LayerNorm

### HÃ m Loss
```
L = Loss_reg + Î»Â·Loss_cls
```
Trong Ä‘Ã³:
- **Regression**: Huber loss (Î´=1.0) hoáº·c Pinball loss (quantile 0.5)
- **Classification**: Binary Cross-Entropy cho direction prediction
- **Î»=0.3** (há»‡ sá»‘ trá»ng sá»‘ configurable)

### Uncertainty Estimation
- **MC-Dropout**: 20 forward passes vá»›i training=True
- **Output**: Mean, Std, Q10, Q90 cho má»—i horizon
- **Entry Rule**: |mean_pred| > fee + buffer AND [Q10, Q90] khÃ´ng chá»©a 0

### Tá»‘i Æ¯u HÃ³a
- **Optimizer**: AdamW (lr=1e-3, weight_decay=1e-4, clipnorm=1.0)
- **Mixed Precision**: FP16 cho GPU optimization
- **Batch Size**: 64 (cÃ³ thá»ƒ tÄƒng lÃªn 256 cho GPU máº¡nh)
- **Early Stopping**: patience=15
- **Memory Management**: tf.data pipeline + cleanup per fold

## ğŸš€ Quy TrÃ¬nh Sá»­ Dá»¥ng

### 1. CÃ i Äáº·t
```bash
python -m venv .venv && source .venv/bin/activate
pip install -U pip && pip install -U -r requirements.txt
```

### 2. Chuáº©n Bá»‹ Dá»¯ Liá»‡u (Cháº¡y 1 láº§n)
```bash
# Thu tháº­p dá»¯ liá»‡u tá»« VnStock API
python src/collect_vnstock.py --tickers FPT HPG VNM --start 2015-01-01 --end 2025-08-28

# Chuáº©n bá»‹ dataset vá»›i 65 features
python src/prepare_dataset.py --config configs/config.yaml
```

### 3. Training Multi-Horizon TCN
```bash
# Multi-horizon vá»›i MC-Dropout uncertainty
python src/train.py --config configs/config.yaml --gpu \
  --horizons 5,10,20 --loss_type huber --lambda_cls 0.3 --n_mc_dropout 20

# Hoáº·c chá»‰ TCN single-horizon (backward compatible)
python src/train.py --config configs/config_baseline.yaml --gpu
```

### 4. Backtesting vá»›i Uncertainty
```bash
# Backtest theo horizon H âˆˆ {5,10,20}
python src/paper_trading.py --config configs/config.yaml --ticker FPT --horizon 10 --model tcn
python src/paper_trading.py --config configs/config.yaml --ticker FPT --horizon 20 --model tcn
```

### 5. Trá»±c Quan HÃ³a Káº¿t Quáº£
Sá»­ dá»¥ng notebook cell Ä‘Ã£ cung cáº¥p Ä‘á»ƒ plot:
- Time-series True vs Predicted cho tá»«ng fold
- Scatter plot vá»›i RMSE/MAE/SMAPE
- Multi-horizon metrics: DA@H, IC@H, Sharpe-like@H

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
ChungKhoanAI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models.py          # TCN-Residual + Multi-horizon heads
â”‚   â”œâ”€â”€ train.py           # Training vá»›i MC-Dropout + CLI overrides
â”‚   â”œâ”€â”€ paper_trading.py   # Uncertainty-aware backtesting
â”‚   â”œâ”€â”€ prepare_dataset.py # 65 technical features + multi-task targets
â”‚   â”œâ”€â”€ ensemble.py        # Ensemble prediction
â”‚   â”œâ”€â”€ backtest.py        # Traditional backtesting
â”‚   â”œâ”€â”€ features.py        # Technical indicators (robust BBands)
â”‚   â”œâ”€â”€ evaluate.py        # DA, IC, Sharpe-like metrics
â”‚   â”œâ”€â”€ collect_vnstock.py # VnStock data collection
â”‚   â””â”€â”€ utils.py           # Utilities + walk-forward splits
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml        # Multi-horizon configuration
â”‚   â””â”€â”€ config_baseline.yaml # Single-horizon baseline
â”œâ”€â”€ reports/               # Results organized by ticker/model
â”‚   â”œâ”€â”€ {TICKER}/
â”‚   â”‚   â”œâ”€â”€ tcn/
â”‚   â”‚   â”‚   â”œâ”€â”€ L60/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ seed{X}/ # Individual seed results
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ metrics.json # DA@5, IC@5, sharpe_like@5, etc.
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ preds_with_uncertainty.json # Mean, std, q10, q90
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ensemble/ # Ensemble results
â”‚   â”‚   â”‚   â””â”€â”€ L90/
â”‚   â”‚   â”œâ”€â”€ gru/           # Comparison models
â”‚   â”‚   â””â”€â”€ lstm/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ datasets/              # Preprocessed time series
â”œâ”€â”€ data/                  # Raw price data
â””â”€â”€ requirements.txt       # Dependencies
```

## âš™ï¸ Cáº¥u HÃ¬nh Chi Tiáº¿t

### Multi-Horizon Config (`configs/config.yaml`)
```yaml
# Core settings
tickers: ["FPT", "HPG", "VNM"]
models: ["tcn", "gru", "lstm"]
lookback: 60
batch_size: 64  # Increase to 256 for stronger GPUs

# Multi-horizon prediction
horizons: [5, 10, 20]
loss_type: huber        # huber | pinball
lambda_cls: 0.3         # Classification loss weight
n_mc_dropout: 20        # MC-Dropout passes

# Trading parameters
trade_fee: 0.002        # 0.2% trading fee
risk_per_trade: 0.01    # 1% risk per trade

# TCN architecture
tcn:
  filters: 64
  kernel_size: 5
  dilations: [1, 2, 4, 8]
  dropout_rate: 0.1
  use_se: true              # Squeeze-Excitation
  use_multitask: true       # Multi-task learning
  weight_decay: 1e-4

# Ensemble settings
ensemble:
  enable: true
  seeds: [42, 123, 456, 789, 999]  # 5 different seeds
```

### CLI Overrides
```bash
# Override any config parameter via command line
python src/train.py --config configs/config.yaml --gpu \
  --horizons 5,10,20 \
  --loss_type pinball \
  --lambda_cls 0.5 \
  --n_mc_dropout 30
```

## ğŸ“Š Káº¿t Quáº£ vÃ  Metrics

### Multi-Horizon Metrics
- **DA@H**: Directional Accuracy táº¡i horizon H
- **IC@H**: Information Coefficient (correlation) táº¡i horizon H  
- **Sharpe-like@H**: Mean(pred) / Std(pred) táº¡i horizon H
- **Traditional**: RMSE, MAE, MAPE, SMAPE (backward compatible)

### Uncertainty Outputs
```json
{
  "mean": [[r5, r10, r20], ...],     // Mean predictions per horizon
  "std": [[Ïƒ5, Ïƒ10, Ïƒ20], ...],      // Standard deviation
  "q10": [[q10_5, q10_10, q10_20], ...], // 10th percentile
  "q90": [[q90_5, q90_10, q90_20], ...], // 90th percentile
  "horizons": [5, 10, 20]
}
```

### Backtesting Results
```json
{
  "equity_curve": [1.0, 1.05, 0.98, ...],
  "max_drawdown": 0.15,
  "winrate": 0.62,
  "trades": 145
}
```

## ğŸ”¬ TÃ­nh NÄƒng TiÃªn Tiáº¿n

### MC-Dropout Uncertainty
- **Training**: Dropout á»Ÿ output heads (rate=0.1)
- **Inference**: 20 forward passes vá»›i training=True
- **Aggregation**: Mean, std, quantiles cho confidence intervals
- **Trading**: Entry chá»‰ khi [Q10, Q90] khÃ´ng chá»©a 0

### Multi-Horizon Learning
- **Targets**: Log-returns táº¡i H=5,10,20 ngÃ y
- **Architecture**: Shared encoder + separate heads per horizon
- **Loss**: Combined regression + classification loss
- **Evaluation**: Horizon-specific metrics

### Advanced Loss Functions
- **Huber Loss**: Robust to outliers (Î´=1.0)
- **Pinball Loss**: Quantile regression (q=0.5)
- **Combined**: L_reg + Î»Â·L_cls vá»›i configurable Î»

### GPU Optimization
- **Mixed Precision**: FP16 training
- **tf.data Pipeline**: Efficient data loading
- **Memory Management**: Cleanup per fold
- **Batch Size**: Auto-scaling based on GPU memory

## ğŸ¯ Chiáº¿n LÆ°á»£c Trading

### Entry Rules (Uncertainty-Aware)
1. **Signal Strength**: |mean_pred| > fee + buffer
2. **Confidence**: [Q10, Q90] khÃ´ng chá»©a 0 (no uncertainty overlap)
3. **Risk Management**: Fixed risk per trade (1% default)

### Exit Rules
- **Time-based**: ÄÃ³ng sau Ä‘Ãºng H ngÃ y
- **Stop Loss**: 2Ã—ATR tá»« entry
- **Take Profit**: 4Ã—ATR tá»« entry

### Portfolio Management
- **Position Sizing**: Risk-based sizing
- **Diversification**: Multiple horizons, multiple tickers
- **Transaction Costs**: Realistic fee modeling (0.2%)

## ğŸ“ˆ Hiá»‡u Suáº¥t Ká»³ Vá»ng

### Multi-Horizon Performance
- **DA@5**: 55-65% (directional accuracy)
- **DA@10**: 52-62%
- **DA@20**: 50-60%
- **IC@5**: 0.05-0.15 (information coefficient)
- **Sharpe-like**: 5-20 (depends on volatility)

### Trading Performance
- **Win Rate**: 55-65%
- **Max Drawdown**: 10-25%
- **Sharpe Ratio**: 0.8-1.5
- **Annual Return**: 15-30% (before costs)

### Ensemble Benefits
- **Variance Reduction**: 10-20% improvement
- **Robustness**: Better out-of-sample performance
- **Uncertainty**: More reliable confidence intervals

## ğŸ› ï¸ Troubleshooting

### Common Issues
1. **GPU Memory**: Reduce batch_size hoáº·c táº¯t ensemble
2. **NaN Metrics**: ÄÃ£ fix vá»›i safe metrics computation
3. **Data Loading**: Check pandas_ta availability
4. **Syntax Errors**: All files Ä‘Ã£ compile OK

### Performance Tuning
```bash
# Increase GPU utilization
# Edit config.yaml:
batch_size: 256          # Increase for more VRAM usage
tcn:
  filters: 96           # Larger model capacity
  dilations: [1,2,4,8,16] # More layers

# Reduce memory usage
n_mc_dropout: 10        # Fewer MC passes
ensemble:
  enable: false         # Disable ensemble
```

## ğŸ§ª Testing vÃ  Validation

### Quick Test
```bash
# Test single ticker, single horizon
python src/train.py --config configs/config.yaml --gpu \
  --horizons 5 --n_mc_dropout 5

# Test backtesting
python src/paper_trading.py --config configs/config.yaml \
  --ticker FPT --horizon 5 --model tcn
```

### Full Pipeline
```bash
# Complete end-to-end test
python src/run_all.py  # If available
```

## ğŸ“š Ná»n Táº£ng NghiÃªn Cá»©u

Triá»ƒn khai nÃ y dá»±a trÃªn:
- **Temporal Convolutional Networks** cho sequence modeling
- **Multi-Task Learning** cho joint regression + classification
- **MC-Dropout** cho Bayesian uncertainty estimation
- **Ensemble Methods** cho variance reduction
- **Walk-Forward Validation** cho realistic evaluation

## ğŸ¤ Má»Ÿ Rá»™ng

### ThÃªm MÃ´ HÃ¬nh Má»›i
1. Implement trong `src/models.py`
2. Update `configs/config.yaml`
3. Test vá»›i multi-horizon pipeline

### ThÃªm Metrics Má»›i
1. Extend `src/evaluate.py`
2. Update training loop trong `src/train.py`
3. Log vÃ o `metrics.json`

### ThÃªm Trading Strategies
1. Extend `src/paper_trading.py`
2. Add new entry/exit rules
3. Implement portfolio optimization

---

**LÆ°u Ã½**: Há»‡ thá»‘ng nÃ y Ä‘Æ°á»£c thiáº¿t káº¿ cho má»¥c Ä‘Ã­ch nghiÃªn cá»©u vÃ  giÃ¡o dá»¥c. LuÃ´n xÃ¡c thá»±c káº¿t quáº£ vÃ  cÃ¢n nháº¯c rá»§i ro thá»‹ trÆ°á»ng trÆ°á»›c khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh giao dá»‹ch thá»±c táº¿.