# ChungKhoanAI - Vietnamese Stock Price Prediction with TCN-Residual

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.12+-orange.svg)](https://www.tensorflow.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

Advanced stock price prediction system using **TCN-Residual (Temporal Convolutional Network with Residual Connections)** architecture for Vietnamese stock market analysis.

## ğŸ¯ Features

- **TCN-Residual Architecture**: State-of-the-art temporal convolutional networks
- **Multi-Task Learning**: Predicts both price and direction
- **Ensemble Learning**: Multiple seeds and window sizes
- **Comprehensive Baselines**: Naive, SMA, EMA, ARIMA, Holt-Winters
- **Production Ready**: Full backtesting and evaluation pipeline
- **Google Colab Support**: Easy cloud deployment

## ğŸ—ï¸ Tá»•ng Quan Kiáº¿n TrÃºc

### MÃ´ HÃ¬nh TCN-Residual
MÃ´ hÃ¬nh cá»‘t lÃµi triá»ƒn khai kiáº¿n trÃºc TCN phá»©c táº¡p vá»›i:

```
Input LÃ—d (L=60, d=features)
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=1) + LayerNorm + ReLU + Dropout(0.1)
     Residual add
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=2) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=4) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> Causal 1D Conv (k=5, f=64, dilation=8) + LN + ReLU + Dropout(0.1) + Residual
 â””â”€> (TÃ¹y chá»n) Squeeze-Excitation (channel attention)
 â””â”€> GlobalAvgPool (theo thá»i gian)
 â””â”€> Head Há»“i quy: Dense(64) â†’ Dense(1)  =>  Å·_reg = rÌ‚_{t+1}
 â””â”€> (TÃ¹y chá»n) Head PhÃ¢n loáº¡i: Dense(64) â†’ Dense(1, sigmoid) =>  pÌ‚(up)
```

### TÃ­nh NÄƒng ChÃ­nh

- **Multi-Task Learning**: Há»c Ä‘á»“ng thá»i há»“i quy (dá»± Ä‘oÃ¡n giÃ¡) vÃ  phÃ¢n loáº¡i (dá»± Ä‘oÃ¡n hÆ°á»›ng)
- **HÃ m Loss TiÃªn tiáº¿n**: Káº¿t há»£p Huber loss + Î»Â·BCE loss
- **Chiáº¿n lÆ°á»£c Ensemble**: 5 seeds Ã— 2 kÃ­ch thÆ°á»›c cá»­a sá»• Ã— nhiá»u kiáº¿n trÃºc
- **Tá»‘i Æ°u hÃ³a Phá»©c táº¡p**: AdamW vá»›i cosine decay + warmup scheduling
- **Walk-Forward Cross-Validation**: XÃ¡c thá»±c chuá»—i thá»i gian thá»±c táº¿

## ğŸ“‹ Äáº·c Táº£ MÃ´ HÃ¬nh

### Tham Sá»‘ Kiáº¿n TrÃºc
- **Äá»™ dÃ i Cá»­a sá»• (L)**: 60 (chÃ­nh), 90 (ensemble)
- **KÃ­ch thÆ°á»›c Kernel (k)**: 5
- **Filters**: 64 (cÃ³ thá»ƒ má»Ÿ rá»™ng Ä‘áº¿n 96-128)
- **Dilations**: [1, 2, 4, 8, (16)]
- **Chuáº©n hÃ³a**: LayerNorm
- **Dropout**: 0.1-0.2
- **Activation**: ReLU

### HÃ m Loss
```
L = Huber(r, rÌ‚) + Î»Â·BCE(y, Å·)
```
Trong Ä‘Ã³:
- Huber loss (Î´=1.0) cho há»“i quy
- Binary Cross-Entropy cho dá»± Ä‘oÃ¡n hÆ°á»›ng
- Î»=0.25 (há»‡ sá»‘ trá»ng sá»‘)

### Tá»‘i Æ¯u HÃ³a
- **Optimizer**: AdamW (lr=1e-3, weight_decay=1e-4)
- **Schedule**: Cosine decay + 5 warmup epochs
- **Gradient Clipping**: norm=1.0
- **Batch Size**: 64
- **Early Stopping**: patience=15

### Chia Dá»¯ Liá»‡u
- **Train**: 60%
- **Validation**: 20%
- **Test**: 20%
- **PhÆ°Æ¡ng phÃ¡p**: Walk-Forward CV (expanding window)

## ğŸš€ Quick Start

### Installation
```bash
# Clone repository
git clone https://github.com/your-username/chungkhoan-ai.git
cd chungkhoan-ai

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# or
.venv\Scripts\activate     # Windows

# Install dependencies
pip install -U pip
pip install -r requirements.txt
pip install statsmodels  # For baseline models
```

### Basic Usage
```bash
# Quick demo with baseline models
python run_baselines.py --tickers FPT HPG VNM

# Compare with deep learning models
python compare_baselines.py
```

### Google Colab (Recommended)
```python
# 1. Upload these files to Colab:
# - colab_research_pipeline.ipynb
# - src/ (code directory)
# - configs/ (config directory)
# - requirements.txt

# 2. Open notebook and run cells step by step
# 3. Download thesis_results.zip when complete

# Note: If you encounter 403 Forbidden errors during data collection,
# the system will automatically fall back to sample data for demonstration.
```

### Full Research Pipeline
```bash
# Complete pipeline for thesis (30-45 minutes)
python research_pipeline.py --tickers FPT HPG VNM
```

Thao tÃ¡c nÃ y cháº¡y toÃ n bá»™ pipeline:
1. Thu tháº­p dá»¯ liá»‡u tá»« VnStock API
2. Ká»¹ thuáº­t tÃ­nh nÄƒng vÃ  chuáº©n bá»‹ dataset
3. Training ensemble Ä‘a seeds
4. Táº¡o dá»± Ä‘oÃ¡n ensemble
5. Backtesting (mÃ´ hÃ¬nh riÃªng láº» + ensemble)

### 3. CÃ¡c BÆ°á»›c Thá»§ CÃ´ng

#### Thu Tháº­p Dá»¯ Liá»‡u
```bash
python src/collect_vnstock.py --tickers FPT HPG VNM --start 2015-01-01 --end 2025-08-28
```

#### Chuáº©n Bá»‹ Dataset (Multi-task)
```bash
python src/prepare_dataset.py --config configs/config.yaml --multitask
```

#### Training vá»›i Ensemble
```bash
python src/train.py --config configs/config.yaml --ensemble
```

#### Táº¡o Dá»± ÄoÃ¡n Ensemble
```bash
python src/ensemble.py --config configs/config.yaml
```

#### Baseline Models (Naive, SMA/EMA, ARIMA)
```bash
# Run baseline models
python run_baselines.py --tickers FPT HPG VNM

# Compare with DL models (predicting prices instead of returns)
python src/prepare_dataset.py --config configs/config_baseline.yaml
python src/train.py --config configs/config_baseline.yaml
python compare_baselines.py
```

#### Backtesting
```bash
# MÃ´ hÃ¬nh riÃªng láº»
python src/backtest.py --config configs/config.yaml

# Ensemble
python src/backtest.py --config configs/config.yaml --ensemble
```

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
ChungKhoanAI/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models.py          # TCN-Residual + cÃ¡c kiáº¿n trÃºc khÃ¡c
â”‚   â”œâ”€â”€ train.py           # Training multi-task vá»›i ensemble
â”‚   â”œâ”€â”€ ensemble.py        # Táº¡o dá»± Ä‘oÃ¡n ensemble
â”‚   â”œâ”€â”€ prepare_dataset.py # Ká»¹ thuáº­t tÃ­nh nÄƒng + multi-task targets
â”‚   â”œâ”€â”€ backtest.py        # Backtesting chiáº¿n lÆ°á»£c
â”‚   â”œâ”€â”€ baseline.py        # Baseline models (Naive, SMA/EMA, ARIMA)
â”‚   â”œâ”€â”€ collect_vnstock.py # Thu tháº­p dá»¯ liá»‡u
â”‚   â”œâ”€â”€ features.py        # Chá»‰ bÃ¡o ká»¹ thuáº­t
â”‚   â”œâ”€â”€ evaluate.py        # Metrics
â”‚   â”œâ”€â”€ utils.py           # Tiá»‡n Ã­ch
â”‚   â””â”€â”€ run_all.py         # Pipeline hoÃ n chá»‰nh
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml        # Cáº¥u hÃ¬nh vá»›i tham sá»‘ TCN
â”œâ”€â”€ reports/               # Káº¿t quáº£ sáº¯p xáº¿p theo ticker/model
â”‚   â”œâ”€â”€ {TICKER}/
â”‚   â”‚   â”œâ”€â”€ tcn/           # Káº¿t quáº£ mÃ´ hÃ¬nh TCN
â”‚   â”‚   â”‚   â”œâ”€â”€ L60/       # KÃ­ch thÆ°á»›c cá»­a sá»• 60
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ seed{X}/ # Káº¿t quáº£ seed riÃªng láº»
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ensemble/ # Káº¿t quáº£ ensemble
â”‚   â”‚   â”‚   â””â”€â”€ L90/       # KÃ­ch thÆ°á»›c cá»­a sá»• 90
â”‚   â”‚   â”œâ”€â”€ gru/           # So sÃ¡nh GRU
â”‚   â”‚   â”œâ”€â”€ baseline/      # Baseline models (Naive, SMA/EMA, ARIMA)
â”‚   â”‚   â””â”€â”€ ensemble/      # Ensemble Ä‘a mÃ´ hÃ¬nh
â”‚   â””â”€â”€ ...
â”œâ”€â”€ datasets/              # Dá»¯ liá»‡u chuá»—i thá»i gian Ä‘Ã£ chuáº©n bá»‹
â”œâ”€â”€ data/                  # Dá»¯ liá»‡u giÃ¡ thÃ´
â”œâ”€â”€ run_baselines.py      # Script cháº¡y baseline models
â”œâ”€â”€ test_tcn.py           # Kiá»ƒm tra validation
â””â”€â”€ requirements.txt       # Dependencies
```

## âš™ï¸ Cáº¥u HÃ¬nh

File `configs/config.yaml` chá»©a táº¥t cáº£ tham sá»‘:

```yaml
tickers: ["FPT", "HPG", "VNM"]
models: ["tcn", "gru", "lstm"]  # TCN lÃ  mÃ´ hÃ¬nh chÃ­nh

# Tham sá»‘ riÃªng cho TCN
tcn:
  filters: 64
  kernel_size: 5
  dilations: [1, 2, 4, 8]
  dropout_rate: 0.1
  use_se: true              # Squeeze-Excitation
  use_multitask: true       # Multi-task learning
  loss_lambda: 0.25         # Î» cho BCE trong combined loss
  weight_decay: 1e-4

# CÃ i Ä‘áº·t ensemble
ensemble:
  enable: true
  seeds: [42, 123, 456, 789, 999]  # 5 seeds khÃ¡c nhau
  voting_method: "average"

ensemble_lookbacks: [60, 90]  # Nhiá»u kÃ­ch thÆ°á»›c cá»­a sá»•
```

## ğŸ“Š Cáº¥u TrÃºc Káº¿t Quáº£

Káº¿t quáº£ Ä‘Æ°á»£c sáº¯p xáº¿p theo:
- **Ticker** (FPT, HPG, VNM)
- **MÃ´ hÃ¬nh** (tcn, gru, lstm)
- **KÃ­ch thÆ°á»›c Cá»­a sá»•** (L60, L90)
- **Seed** (seed42, seed123, v.v.)
- **Ensemble** (dá»± Ä‘oÃ¡n káº¿t há»£p)

Má»—i thÆ° má»¥c káº¿t quáº£ chá»©a:
- `metrics.json`: Metrics hiá»‡u suáº¥t
- `preds.json`: Dá»± Ä‘oÃ¡n (há»“i quy + phÃ¢n loáº¡i)
- `backtest_summary.json`: Hiá»‡u suáº¥t giao dá»‹ch
- `backtest_curve.csv`: MÃ´ phá»ng giao dá»‹ch chi tiáº¿t
- `backtest_equity.png`: Trá»±c quan hÃ³a Ä‘Æ°á»ng cong vá»‘n

## ğŸ”¬ Multi-Task Learning

Há»‡ thá»‘ng dá»± Ä‘oÃ¡n Ä‘á»“ng thá»i:
1. **Há»“i quy**: Log return ngÃ y tiáº¿p theo (liÃªn tá»¥c)
2. **PhÃ¢n loáº¡i**: HÆ°á»›ng giÃ¡ (tÄƒng/giáº£m)

Lá»£i Ã­ch:
- Dá»± Ä‘oÃ¡n hÆ°á»›ng á»•n Ä‘á»‹nh hÆ¡n
- Quáº£n lÃ½ rá»§i ro tá»‘t hÆ¡n
- TÃ­n hiá»‡u giao dá»‹ch cáº£i thiá»‡n

## ğŸ¯ Chiáº¿n LÆ°á»£c Ensemble

Ensemble káº¿t há»£p:
- **5 seeds** Ä‘á»ƒ giáº£m phÆ°Æ¡ng sai
- **2 kÃ­ch thÆ°á»›c cá»­a sá»•** (60, 90) cho nhá»¯ng gÃ³c nhÃ¬n khÃ¡c nhau
- **Nhiá»u kiáº¿n trÃºc** (TCN + GRU) cho sá»± Ä‘a dáº¡ng

**Hiá»‡u suáº¥t Ká»³ vá»ng**: Giáº£m MAPE 5-15% so vá»›i mÃ´ hÃ¬nh Ä‘Æ¡n láº»

## ğŸ“ˆ Backtesting

Há»‡ thá»‘ng cung cáº¥p backtesting toÃ n diá»‡n:
- **Metrics**: Tá»· lá»‡ Sharpe, max drawdown, tá»· lá»‡ tháº¯ng
- **MÃ´ phá»ng Giao dá»‹ch**: Chi phÃ­ giao dá»‹ch, thá»±c thi thá»±c táº¿
- **Multi-Task**: ÄÃ¡nh giÃ¡ riÃªng biá»‡t cho tÃ­n hiá»‡u há»“i quy vs phÃ¢n loáº¡i
- **Trá»±c quan hÃ³a**: ÄÆ°á»ng cong vá»‘n vÃ  so sÃ¡nh hiá»‡u suáº¥t

## ğŸ› ï¸ TÃ­nh NÄƒng TiÃªn Tiáº¿n

### LÃªn Lá»‹ch Learning Rate
- **Warmup**: TÄƒng tuyáº¿n tÃ­nh trong 5 epochs
- **Cosine Decay**: Giáº£m mÆ°á»£t mÃ  vá» gáº§n zero
- **Gradient Clipping**: NgÄƒn cháº·n gradient exploding

### Regularization
- **Weight Decay**: L2 regularization qua AdamW
- **Dropout**: Regularization ngáº«u nhiÃªn
- **Layer Normalization**: Training á»•n Ä‘á»‹nh

### Ká»¹ Thuáº­t TÃ­nh NÄƒng
- **Chá»‰ BÃ¡o Ká»¹ Thuáº­t**: 50+ chá»‰ bÃ¡o
- **Bá»‘i Cáº£nh Thá»‹ TrÆ°á»ng**: TÆ°Æ¡ng quan chá»‰ sá»‘, beta
- **PhÃ¡t Hiá»‡n Cháº¿ Äá»™**: Cháº¿ Ä‘á»™ biáº¿n Ä‘á»™ng vÃ  xu hÆ°á»›ng
- **TÃ­nh NÄƒng Lá»‹ch**: NgÃ y trong tuáº§n, tÃ­nh mÃ¹a vá»¥

## ğŸ§ª Kiá»ƒm Tra

Cháº¡y kiá»ƒm tra validation:
```bash
python test_tcn.py
```

Hoáº·c validation Ä‘Æ¡n giáº£n:
```bash
python simple_test.py
```

## ğŸ“š Ná»n Táº£ng NghiÃªn Cá»©u

Triá»ƒn khai nÃ y dá»±a trÃªn:
- **Temporal Convolutional Networks** cho mÃ´ hÃ¬nh hÃ³a chuá»—i
- **Residual Connections** cho á»•n Ä‘á»‹nh training
- **Multi-Task Learning** cho dá»± Ä‘oÃ¡n máº¡nh máº½
- **Ensemble Methods** cho giáº£m phÆ°Æ¡ng sai
- **Walk-Forward Validation** cho Ä‘Ã¡nh giÃ¡ thá»±c táº¿

## ğŸ”„ VÃ­ Dá»¥ Sá»­ Dá»¥ng

### Chá»‰ Training TCN
```bash
python src/train.py --config configs/config.yaml
```

### Cáº¥u HÃ¬nh TCN TÃ¹y Chá»‰nh
Sá»­a Ä‘á»•i `configs/config.yaml`:
```yaml
tcn:
  filters: 96           # TÄƒng sá»©c chá»©a
  dilations: [1,2,4,8,16] # ThÃªm layers
  dropout_rate: 0.15    # Regularization nhiá»u hÆ¡n
```

### Ensemble vá»›i MÃ´ hÃ¬nh TÃ¹y chá»‰nh
```bash
python src/ensemble.py --config configs/config.yaml --models tcn gru
```

## ğŸ¯ Hiá»‡u Suáº¥t Ká»³ Vá»ng

**Metrics Baseline** (pháº¡m vi thÆ°á»ng tháº¥y):
- **RMSE**: 0.015-0.025
- **MAPE**: 8-15%
- **Tá»· lá»‡ Sharpe**: 0.5-1.2
- **Max Drawdown**: 10-25%
- **Äá»™ chÃ­nh xÃ¡c PhÃ¢n loáº¡i**: 52-58%

**Cáº£i thiá»‡n Ensemble**: Tá»‘t hÆ¡n 5-15% so vá»›i mÃ´ hÃ¬nh Ä‘Æ¡n láº»

## ğŸ¤ ÄÃ³ng GÃ³p

Äá»ƒ má»Ÿ rá»™ng há»‡ thá»‘ng:
1. ThÃªm mÃ´ hÃ¬nh má»›i trong `src/models.py`
2. Cáº­p nháº­t cáº¥u hÃ¬nh trong `configs/config.yaml`
3. Má»Ÿ rá»™ng logic ensemble trong `src/ensemble.py`
4. ThÃªm tests trong `test_tcn.py`

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the project
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“§ Contact

For questions or support, please open an issue on GitHub.

---

**Note**: This system is designed for research and educational purposes. Always validate results and consider market risks before making trading decisions.